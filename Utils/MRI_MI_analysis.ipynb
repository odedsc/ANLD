{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e6adcc-6d3d-4cd0-88f9-0a58417a33e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7861252-8f31-477e-846f-d2830bd63574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f603d-d143-40f6-a333-06aad8556de2",
   "metadata": {},
   "source": [
    "## 3DMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157dfa0-bd1d-428e-8186-6c1d7c4f9304",
   "metadata": {},
   "source": [
    "### Original model including everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd1c24-dbd2-4027-9c96-dbd561b5614b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "models_folder = './3DMM/UHM_models/'\n",
    "currnet_model = 'UHM' \n",
    "\n",
    "# UHM model with all the components fused together (i.e. ears, inner mouth, and teeth)\n",
    "model_name = 'head_model_global_align'\n",
    "\n",
    "model_file = open(models_folder + model_name + '.pkl', 'rb')\n",
    "model_dict = pickle.load(model_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218f9a9-2197-4974-8c2d-d1b0e52934ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning coordinates system to be in millimeter units\n",
    "scale_factor = 100\n",
    "\n",
    "# get model parameteres\n",
    "mean_shape = scale_factor*model_dict['Mean']\n",
    "mean_shape_CCS = mean_shape.reshape(-1,3)\n",
    "eigen_vec = model_dict['Eigenvectors']\n",
    "eigen_vec_num =  model_dict['Eigenvectors'].shape[1]\n",
    "eigen_val = model_dict['EigenValues']\n",
    "trilist = model_dict['Trilist']\n",
    "vertices_num = model_dict['Number_of_vertices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785cab1e-ea39-401a-b3cf-fb25e39cc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules (landmarks and masks)\n",
    "modules_folder = models_folder + '/Landmarks and masks/'\n",
    "\n",
    "modules_to_load = ['68_land_idxs'] # EEG_10_20_full_model / '49_plus_ears_land_idxs' / '68_land_idxs'\n",
    "\n",
    "landmarks = []\n",
    "landmarks_names = []\n",
    "landmarks_groups = []\n",
    "\n",
    "for currnet_module_name in modules_to_load:\n",
    "    module_file = open(modules_folder + currnet_module_name + '.pkl', 'rb')\n",
    "    currnet_module = pickle.load(module_file)\n",
    "    module_file.close()\n",
    "    if currnet_module_name=='EEG_10_20':\n",
    "        currnet_module_names = list(currnet_module.keys())\n",
    "        currnet_module = np.asarray(list(currnet_module.values()))\n",
    "    else:\n",
    "        currnet_module_names = list(map(str, 1+np.arange(len(currnet_module))))\n",
    "        \n",
    "    landmarks.append(currnet_module)\n",
    "    landmarks_names.append(currnet_module_names)\n",
    "    landmarks_groups.append(np.arange(len(currnet_module)))\n",
    "\n",
    "# turn list of lists into one list\n",
    "landmarks = [item for items in landmarks for item in items]\n",
    "landmarks_names = [item for items in landmarks_names for item in items]\n",
    "\n",
    "num_of_landmarks = len(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad01fd-85af-4bf0-b39c-c1db74860057",
   "metadata": {},
   "source": [
    "### Lighter model including everything but eyes, teeth and inner mouth cavity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c2a5a-04d3-486a-9b4e-d79907153757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "light_models_folder = './3DMM/UHM_models/'\n",
    "light_currnet_model = 'UHM' \n",
    "\n",
    "# UHM model with all the components fused together (i.e. ears, inner mouth, and teeth)\n",
    "light_model_name = 'head_model_global_align_no_mouth_and_eyes'\n",
    "\n",
    "light_model_file = open(light_models_folder + light_model_name + '.pkl', 'rb')\n",
    "light_model_dict = pickle.load(light_model_file)\n",
    "light_model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7184d8-deb9-4e99-8ecc-9cb166b2957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning cartesian coordinates system to be in millimeter units\n",
    "light_scale_factor = 100\n",
    "\n",
    "# get model parameteres\n",
    "light_mean_shape = light_scale_factor*light_model_dict['Mean']\n",
    "light_mean_shape_CCS = light_mean_shape.reshape(-1,3)\n",
    "light_eigen_vec = light_model_dict['Eigenvectors']\n",
    "light_eigen_vec_num =  light_model_dict['Eigenvectors'].shape[1]\n",
    "light_eigen_val = light_model_dict['EigenValues']\n",
    "light_trilist = light_model_dict['Trilist']\n",
    "light_vertices_num = light_model_dict['Number_of_vertices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d3845-3879-4f6e-8161-44134fc644d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules (landmarks and masks)\n",
    "modules_folder = models_folder + '/Landmarks and masks/'\n",
    "\n",
    "modules_to_load = ['EEG_10_20'] # EEG_10_20 / '49_plus_ears_land_idxs' / '68_land_idxs'\n",
    "\n",
    "light_landmarks = []\n",
    "light_landmarks_names = []\n",
    "light_landmarks_groups = []\n",
    "\n",
    "for currnet_module_name in modules_to_load:\n",
    "    module_file = open(modules_folder + currnet_module_name + '.pkl', 'rb')\n",
    "    currnet_module = pickle.load(module_file)\n",
    "    module_file.close()\n",
    "    if currnet_module_name=='EEG_10_20':\n",
    "        currnet_module_names = list(currnet_module.keys())\n",
    "        currnet_module = np.asarray(list(currnet_module.values()))\n",
    "    else:\n",
    "        currnet_module_names = list(map(str, 1+np.arange(len(currnet_module))))\n",
    "        \n",
    "    light_landmarks.append(currnet_module)\n",
    "    light_landmarks_names.append(currnet_module_names)\n",
    "    light_landmarks_groups.append(np.arange(len(currnet_module)))\n",
    "\n",
    "# turn list of lists into one list\n",
    "light_landmarks = [item for items in light_landmarks for item in items]\n",
    "light_landmarks_names = [item for items in light_landmarks_names for item in items]\n",
    "\n",
    "num_of_light_landmarks = len(light_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f7998-0927-4f41-94cb-ac63bf4b299b",
   "metadata": {},
   "source": [
    "### Matching landmark indices between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14af887-31ac-4624-83c0-aaabfe8ede6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_facial_landmarks = landmarks\n",
    "\n",
    "for current_landmark_index, current_landmark_vertex in enumerate(landmarks):\n",
    "    original_model_coordinates = mean_shape_CCS[current_landmark_vertex]\n",
    "    new_model_vertex_diffs = np.linalg.norm(light_mean_shape_CCS-original_model_coordinates, axis=1)\n",
    "    light_facial_landmarks[current_landmark_index] = np.argmin(new_model_vertex_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a18f2-e11c-4d8f-8bc2-de4d3c607ab9",
   "metadata": {},
   "source": [
    "### Model Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ac270-1a56-4a1a-b5c6-5747b6c45256",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_light_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c8bf4-dd4a-4dfb-9c0d-105279174a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if choose_light_model:\n",
    "    landmarks = np.concatenate((light_landmarks, light_facial_landmarks))\n",
    "    landmarks_names = list(np.concatenate((light_landmarks_names, landmarks_names)))\n",
    "    mean_shape = light_mean_shape\n",
    "    mean_shape_CCS = light_mean_shape_CCS\n",
    "    eigen_vec = light_eigen_vec\n",
    "    eigen_vec_num =  light_eigen_vec_num\n",
    "    eigen_val = light_eigen_val\n",
    "    trilist = light_trilist\n",
    "    vertices_num = light_vertices_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949313f1-06d2-49d4-8993-611504a35125",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfad12-7777-41e0-9a8e-05b8334af447",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_landmarks_names = np.array([37, 40, 43, 46, 49, 55, 31, 9])\n",
    "rigid_facial_landmarks_names = np.array([37, 40, 43, 46, 28, 1, 17])\n",
    "\n",
    "center_of_the_eyebrows = np.array([20, 25])\n",
    "corners_of_the_eyebrows = np.array([18, 22, 23, 27])\n",
    "corners_of_the_eyes = np.array([37, 40, 43, 46])\n",
    "sides_of_the_face = np.array([1, 17])\n",
    "nose_bone = np.array([28, 31])\n",
    "lower_nose = np.array([32, 34, 36])\n",
    "corners_of_the_mouth = np.array([49, 55])\n",
    "chin = np.array([9])\n",
    "\n",
    "facial_landmarks = np.concatenate((center_of_the_eyebrows, corners_of_the_eyebrows, corners_of_the_eyes, sides_of_the_face, nose_bone, lower_nose))\n",
    "                                   #,corners_of_the_mouth, chin))\n",
    "selected_facial_indices = np.sort(facial_landmarks+num_of_light_landmarks-1)\n",
    "\n",
    "selected_EEG_10_20_landmark_names = light_landmarks_names\n",
    "selected_EEG_10_20_indices = []\n",
    "for current_index, current_landmark_name in enumerate(selected_EEG_10_20_landmark_names):\n",
    "    selected_EEG_10_20_indices.append(landmarks_names.index(current_landmark_name))\n",
    "selected_EEG_10_20_indices = np.asarray(selected_EEG_10_20_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1843b-9990-4b81-b9af-4608d8004e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_facial_landmarks_names = ['1', '2', '3', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',\n",
    "                        '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48']\n",
    "MRI_facial_landmarks = [int(current_landmark)+20 for current_landmark in MRI_facial_landmarks_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92549f2c-63c7-47a2-8634-4d6344e5c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = np.concatenate((MRI_facial_landmarks, selected_EEG_10_20_indices))\n",
    "selected_indices_names = np.take(landmarks_names, selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fcc0b-9003-4a90-9cd3-867b917f447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {}\n",
    "feature_sets['eye corners & eyebrow corners'] = np.concatenate((corners_of_the_eyebrows, corners_of_the_eyes))\n",
    "feature_sets['eye corners & eyebrow centers'] = np.concatenate((center_of_the_eyebrows, corners_of_the_eyes))\n",
    "feature_sets['eye corners & eyebrow corners and center'] = np.concatenate((center_of_the_eyebrows, corners_of_the_eyebrows, corners_of_the_eyes))\n",
    "feature_sets['eye corners & nose bone'] = np.concatenate((corners_of_the_eyes, nose_bone))\n",
    "feature_sets['nose bone & lower nose'] = np.concatenate((nose_bone, lower_nose))\n",
    "feature_sets['MRI_facial_landmarks'] = np.array(MRI_facial_landmarks)\n",
    "\n",
    "for current_key in feature_sets:\n",
    "    feature_sets[current_key] = feature_sets[current_key]+num_of_light_landmarks-1\n",
    "    feature_sets[current_key] = list(map(str, feature_sets[current_key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f931139-d461-4757-9868-0dd28a95fcb0",
   "metadata": {},
   "source": [
    "# IXI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076aa21-e004-4caa-a290-b049c655fb64",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234902b-7cbc-46ca-8324-3239875af3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_scale_factor = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047906bc-bb4e-4de8-81bc-79bd0f2b1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = './MRI_datasets/'\n",
    "current_dataset_name = 'IXI'\n",
    "dataset_filename = 'Dataset.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3f100-7212-4a63-b176-8124970e37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_subject_dataframe = pd.ExcelFile(datasets_folder+current_dataset_name+'/'+dataset_filename)\n",
    "current_sheet_names = current_subject_dataframe.sheet_names\n",
    "current_num_of_sheets = len(current_sheet_names)\n",
    "\n",
    "skin_coordinates_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Skin coordinates')\n",
    "skin_normals_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Skin normals')\n",
    "skin_geodesic_distances_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Skin distances')\n",
    "inverse_matrices_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Inverse transformations')\n",
    "stats_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feda112-c9cf-4f8b-8d6f-4b9421076792",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_coordinates_df = pd.read_excel(datasets_folder+current_dataset_name+'/'+dataset_filename, sheet_name=skin_coordinates_index, index_col=0)\n",
    "skin_geodesic_distances_df = pd.read_excel(datasets_folder+current_dataset_name+'/'+dataset_filename, sheet_name=skin_geodesic_distances_index, index_col=0)\n",
    "stats_df = pd.read_excel(datasets_folder+current_dataset_name+'/'+dataset_filename, sheet_name=stats_index, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde8485-83e7-4694-8da5-a6807f94ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_coordinates_columns_names = list(skin_coordinates_df.columns)\n",
    "only_coordinates_columns_indices = []\n",
    "\n",
    "for i in range(len(skin_coordinates_columns_names)):\n",
    "    if 'indices' not in skin_coordinates_columns_names[i]:\n",
    "        only_coordinates_columns_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a5316-392d-49fb-a3aa-4abc193e3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    max_euclidean_distance = 75e-3\n",
    "\n",
    "    relevant_indices = []\n",
    "    for desired_landmark_index, desired_landmark_name in enumerate(skin_coordinates_df.index[:num_of_light_landmarks]):\n",
    "        desired_landmark_data = skin_coordinates_df.loc[desired_landmark_name, :]\n",
    "        desired_landmark_subjects_coordinates = desired_landmark_data.iloc[np.array(only_coordinates_columns_indices)]\n",
    "        desired_landmark_subjects_coordinates = np.array(desired_landmark_subjects_coordinates).reshape(-1, 3)\n",
    "        if np.where(np.isnan(desired_landmark_subjects_coordinates)==True)[0].size>0:\n",
    "            valid_coordinates_rows = np.unique(np.where(np.isnan(desired_landmark_subjects_coordinates)==False)[0])\n",
    "        else:\n",
    "            valid_coordinates_rows = np.arange(desired_landmark_subjects_coordinates.shape[0])\n",
    "\n",
    "        valid_rows = valid_coordinates_rows\n",
    "\n",
    "        desired_landmark_coordinates_mean = np.mean(desired_landmark_subjects_coordinates[valid_rows, :], axis=0)\n",
    "        euclidean_distances = np.linalg.norm(desired_landmark_subjects_coordinates[valid_rows, :]-desired_landmark_coordinates_mean, axis=1)\n",
    "        desired_landmark_relevant_indices = np.where(euclidean_distances<max_euclidean_distance)[0]\n",
    "        relevant_indices.append(desired_landmark_relevant_indices)\n",
    "\n",
    "    only_valid_score_subjects_rows = relevant_indices[0]\n",
    "    for desired_landmark_index, desired_landmark_name in enumerate(skin_coordinates_df.index[:num_of_light_landmarks]):\n",
    "        only_valid_score_subjects_rows = np.intersect1d(relevant_indices[desired_landmark_index], only_valid_score_subjects_rows)\n",
    "else:\n",
    "    score_ratio_threshold = 1\n",
    "    only_valid_score_subjects_rows = np.sort(np.argsort(stats_df.loc['unique_correspondence_final_loss', :].values)[:int(score_ratio_threshold*stats_df.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703fbe7-ac10-4fce-8ec2-6fc063089f3b",
   "metadata": {},
   "source": [
    "# ADNI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1f6a0-2ba2-4ad7-b279-ba84b2f5f53d",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d6b7b-224b-442f-a6e2-8e96cc330354",
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_scale_factor = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1fe390-6527-470b-b26a-a008ac2351d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = './MRI_datasets/'\n",
    "current_dataset_name = 'ADNI'\n",
    "dataset_filename = 'Dataset.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5ac38-a98c-493b-8fbd-8f53ba022a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_subject_dataframe = pd.ExcelFile(datasets_folder+current_dataset_name+'/'+dataset_filename)\n",
    "current_sheet_names = current_subject_dataframe.sheet_names\n",
    "current_num_of_sheets = len(current_sheet_names)\n",
    "\n",
    "skin_coordinates_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Skin coordinates')\n",
    "skin_normals_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Skin normals')\n",
    "skin_geodesic_distances_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Skin distances')\n",
    "inverse_matrices_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Inverse transformations')\n",
    "stats_index = next(i for i in range(len(current_sheet_names)) if current_sheet_names[i]=='Stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64734cf9-8ea5-483f-873f-c75d1f7ad9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_coordinates_df = pd.read_excel(datasets_folder+current_dataset_name+'/'+dataset_filename, sheet_name=skin_coordinates_index, index_col=0)\n",
    "skin_geodesic_distances_df = pd.read_excel(datasets_folder+current_dataset_name+'/'+dataset_filename, sheet_name=skin_geodesic_distances_index, index_col=0)\n",
    "stats_df = pd.read_excel(datasets_folder+current_dataset_name+'/'+dataset_filename, sheet_name=stats_index, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a517e72-f74b-45e9-a3d4-ba827de5897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_coordinates_columns_names = list(skin_coordinates_df.columns)\n",
    "only_coordinates_columns_indices = []\n",
    "\n",
    "for i in range(len(skin_coordinates_columns_names)):\n",
    "    if 'indices' not in skin_coordinates_columns_names[i]:\n",
    "        only_coordinates_columns_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982b73c-35c4-4bee-a76b-022998355033",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    max_euclidean_distance = 75e-3\n",
    "\n",
    "    relevant_indices = []\n",
    "    for desired_landmark_index, desired_landmark_name in enumerate(skin_coordinates_df.index[:num_of_light_landmarks]):\n",
    "        desired_landmark_data = skin_coordinates_df.loc[desired_landmark_name, :]\n",
    "        desired_landmark_subjects_coordinates = desired_landmark_data.iloc[np.array(only_coordinates_columns_indices)]\n",
    "        desired_landmark_subjects_coordinates = np.array(desired_landmark_subjects_coordinates).reshape(-1, 3)\n",
    "        if np.where(np.isnan(desired_landmark_subjects_coordinates)==True)[0].size>0:\n",
    "            valid_coordinates_rows = np.unique(np.where(np.isnan(desired_landmark_subjects_coordinates)==False)[0])\n",
    "        else:\n",
    "            valid_coordinates_rows = np.arange(desired_landmark_subjects_coordinates.shape[0])\n",
    "\n",
    "        valid_rows = valid_coordinates_rows\n",
    "\n",
    "        desired_landmark_coordinates_mean = np.mean(desired_landmark_subjects_coordinates[valid_rows, :], axis=0)\n",
    "        euclidean_distances = np.linalg.norm(desired_landmark_subjects_coordinates[valid_rows, :]-desired_landmark_coordinates_mean, axis=1)\n",
    "        desired_landmark_relevant_indices = np.where(euclidean_distances<max_euclidean_distance)[0]\n",
    "        relevant_indices.append(desired_landmark_relevant_indices)\n",
    "\n",
    "    only_valid_score_subjects_rows = relevant_indices[0]\n",
    "    for desired_landmark_index, desired_landmark_name in enumerate(skin_coordinates_df.index[:num_of_light_landmarks]):\n",
    "        only_valid_score_subjects_rows = np.intersect1d(relevant_indices[desired_landmark_index], only_valid_score_subjects_rows)\n",
    "else:\n",
    "    score_ratio_threshold = 1\n",
    "    only_valid_score_subjects_rows = np.sort(np.argsort(stats_df.loc['unique_correspondence_final_loss', :].values)[:int(score_ratio_threshold*stats_df.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c385ffd-81bf-4482-ad19-31126b315b2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Mathematical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fb6a8-a2ce-4a80-989d-7e9c47f45978",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_relevant_coordinates_df = skin_coordinates_df.iloc[:, np.array(only_coordinates_columns_indices)].T.iloc[:, np.concatenate((selected_EEG_10_20_indices, np.arange(21,skin_coordinates_df.shape[0]-2)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c59d2d-0c68-4d70-8baf-8d9ae31f4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_coordinates_reshaped = np.zeros((int(skin_relevant_coordinates_df.shape[0]/3), skin_relevant_coordinates_df.shape[1]*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c509803-4642-485e-bdfd-7853a5156b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(skin_coordinates_reshaped.shape[0]):\n",
    "    skin_coordinates_reshaped[i, :] = skin_relevant_coordinates_df.values.reshape(int(skin_relevant_coordinates_df.shape[0]/3), skin_relevant_coordinates_df.shape[1]*3)[i, :].reshape(-1, skin_relevant_coordinates_df.shape[1]).T.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e07a4-cb1f-4ebe-af41-c4b249fb358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiindex_up_names = list(np.repeat(selected_indices_names, 3))\n",
    "multiindex_down_names = ['x', 'y', 'z']*len(multiindex_up_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c936c09-c291-46a4-b4fc-ca2b350afe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_relevant_coordinates_df = pd.DataFrame(data=skin_coordinates_reshaped, \n",
    "                                            columns=pd.MultiIndex.from_tuples(zip(multiindex_up_names, multiindex_down_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865e383-b141-44fb-b296-b6d47b2237e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kernel density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd39d0c-8b7a-401d-b261-d5411cab9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_based_empirical_risk(X, h):\n",
    "    # Define shortcuts for K K2 and K_ast\n",
    "    K = lambda u: 1/np.sqrt(2*np.pi) * np.exp(-u**2 / 2)  # Define the kernel N(0,1)\n",
    "    K2 = lambda u: 1/np.sqrt(2*np.pi * 2) * np.exp(-u**2 / (2 * 2))  # Define the kernel with sigma^2=2\n",
    "    K_ast = lambda u: K2(u) - 2*K(u)    \n",
    "    n = len(X)\n",
    "    J = 2/(n*h) * K(0)  #  Left term [1] pag. 316, Eq (20.25)\n",
    "    for X_i in X:\n",
    "        for X_j in X:\n",
    "            J += 1 / (h * n**2) * K_ast(np.linalg.norm(X_i-X_j)/h)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c04ab-a17b-472e-abb5-720fb1e91660",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_axis_grid_size = 4\n",
    "marginal_axis_grid_size = int(1.5*joint_axis_grid_size)\n",
    "if (marginal_axis_grid_size%2)==1:\n",
    "    marginal_axis_grid_size+=1\n",
    "\n",
    "surface_count = 32\n",
    "\n",
    "bw_risk_estimation_samples_percentage=0.1\n",
    "bw_risk_estimation_indices = np.sort(np.random.choice(skin_relevant_coordinates_df.values.shape[0],\n",
    "                                 int(skin_relevant_coordinates_df.values.shape[0]*bw_risk_estimation_samples_percentage),\n",
    "                                                   replace=False))\n",
    "bw_options = np.linspace(2.5, 7.5, 11)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fd602-bf67-4629-afaf-de88163b24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_selected_indices = np.concatenate((selected_EEG_10_20_indices, np.array(MRI_facial_landmarks)))\n",
    "all_selected_indices_names = np.take(landmarks_names, all_selected_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baabe18-bdd7-4bce-a0ed-32fd29846b1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Probability distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c9870-43c0-409e-bf8c-9f6e59b7da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_list = []\n",
    "\n",
    "if 0: # for PMF visualizations\n",
    "    distribution_function_values_mat = np.zeros((len(all_selected_indices_names), marginal_axis_grid_size**3))\n",
    "    axis_diff = marginal_axis_grid_size-joint_axis_grid_size\n",
    "    linspace_size = marginal_axis_grid_size\n",
    "else: # for joint PMF and MI values\n",
    "    distribution_function_values_mat = np.zeros((len(all_selected_indices_names), joint_axis_grid_size**3))\n",
    "    axis_diff = 0\n",
    "    linspace_size = joint_axis_grid_size\n",
    "    \n",
    "#for desired_landmark_index, desired_landmark_name in enumerate(landmarks_names[:1]):\n",
    "for desired_landmark_index, desired_landmark_name in enumerate(all_selected_indices_names):\n",
    "    print((\"Started \" + desired_landmark_name))\n",
    "    current_samples = skin_relevant_coordinates_df.loc[:, desired_landmark_name]\n",
    "    current_samples = current_samples[~current_samples.isnull().any(axis=1)]\n",
    "    current_samples = current_samples.values[np.where(current_samples.values.all(axis=1))[0], :]\n",
    "    current_risk_estimation_samples = skin_relevant_coordinates_df.loc[bw_risk_estimation_indices, desired_landmark_name].values\n",
    "\n",
    "    current_J = [kernel_based_empirical_risk(current_risk_estimation_samples, current_bw) for current_bw in bw_options]\n",
    "    selected_bw = bw_options[np.argmin(current_J)]\n",
    "    print(selected_bw)\n",
    "\n",
    "    current_kde = KernelDensity(kernel=\"gaussian\", bandwidth=selected_bw)\n",
    "    current_kde.fit(current_samples)\n",
    "    \n",
    "    x_coordinates = current_samples[:, 0]\n",
    "    x_coordinates_mean = np.mean(x_coordinates)\n",
    "    x_coordinates_std = np.std(x_coordinates)\n",
    "    x_min = x_coordinates_mean-3*x_coordinates_std\n",
    "    x_max = x_coordinates_mean+3*x_coordinates_std\n",
    "    x_bin_width = (x_max-x_min)/joint_axis_grid_size\n",
    "    x_grid = np.linspace(x_min+0.5*x_bin_width-(0.5*axis_diff*x_bin_width), x_max-0.5*x_bin_width+(0.5*axis_diff*x_bin_width), linspace_size)\n",
    "\n",
    "    y_coordinates = current_samples[:, 1]\n",
    "    y_coordinates_mean = np.mean(y_coordinates)\n",
    "    y_coordinates_std = np.std(y_coordinates)\n",
    "    y_min = y_coordinates_mean-3*y_coordinates_std\n",
    "    y_max = y_coordinates_mean+3*y_coordinates_std\n",
    "    y_bin_width = (y_max-y_min)/joint_axis_grid_size\n",
    "    y_grid = np.linspace(y_min+0.5*y_bin_width-(0.5*axis_diff*y_bin_width), y_max-0.5*y_bin_width+(0.5*axis_diff*y_bin_width), linspace_size)\n",
    "\n",
    "    z_coordinates = current_samples[:, 2]\n",
    "    z_coordinates_mean = np.mean(z_coordinates)\n",
    "    z_coordinates_std = np.std(z_coordinates)\n",
    "    z_min = z_coordinates_mean-3*z_coordinates_std\n",
    "    z_max = z_coordinates_mean+3*z_coordinates_std\n",
    "    z_bin_width = (z_max-z_min)/joint_axis_grid_size\n",
    "    z_grid = np.linspace(z_min+0.5*z_bin_width-(0.5*axis_diff*z_bin_width), z_max-0.5*z_bin_width+(0.5*axis_diff*z_bin_width), linspace_size)\n",
    "    \n",
    "    X, Y, Z = np.meshgrid(x_grid, y_grid, z_grid)\n",
    "    coordinates_list.append([X, Y, Z])\n",
    "    xyz = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "    \n",
    "    distribution_function_values = current_kde.score_samples(xyz)\n",
    "    distribution_function_values = np.exp(distribution_function_values)\n",
    "    distribution_function_values = distribution_function_values/np.sum(distribution_function_values)\n",
    "    \n",
    "    distribution_function_values_mat[desired_landmark_index, :] = distribution_function_values\n",
    "    \n",
    "    if 0:\n",
    "        fig = go.Figure(data=go.Volume(\n",
    "            x=X.flatten(),\n",
    "            y=Y.flatten(),\n",
    "            z=Z.flatten(),\n",
    "            value=distribution_function_values,\n",
    "            opacity=1,\n",
    "            surface_count=surface_count,\n",
    "            ))\n",
    "        fig.update_layout(title_text=(desired_landmark_name+' distribution function'+\"\\ndataset: \"+dataset_filename), title_x=0.5)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7594219-338e-4fda-b800-17e8e5407f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3d scatter\n",
    "desired_landmark_plot = '3'\n",
    "for desired_landmark_index, desired_landmark_name in enumerate(all_selected_indices_names):\n",
    "    if desired_landmark_name!=desired_landmark_plot:\n",
    "        continue\n",
    "    current_samples = skin_relevant_coordinates_df.loc[:, desired_landmark_name]\n",
    "    current_samples = current_samples[~current_samples.isnull().any(axis=1)]\n",
    "    current_samples = current_samples.values[np.where(current_samples.values.all(axis=1))[0], :]\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(x=current_samples[:, 0],\n",
    "                    y=current_samples[:, 1],\n",
    "                    z=current_samples[:, 2]\n",
    "                    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1aa88e-ff6e-4ce6-a491-81eeffca6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    array_folder = \"./3DMM/Statistical_analysis/\"\n",
    "    array_filename = (current_dataset_name+\"_PMF_\"+str(joint_axis_grid_size))\n",
    "    array_filetype = '.npy'\n",
    "\n",
    "    array_path = array_folder + array_filename + array_filetype\n",
    "    \n",
    "    if 1:\n",
    "        with open(array_path, 'wb') as file:\n",
    "            np.save(file, distribution_function_values_mat)\n",
    "    else:\n",
    "        with open(array_path, 'rb') as file:\n",
    "            distribution_function_values_mat = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97765b95-5641-45f2-ad1e-512e92352774",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_index=2    \n",
    "X, Z, Y = coordinates_list[current_index]\n",
    "\n",
    "current_landmark_distribution_function_values = distribution_function_values_mat[current_index, :]\n",
    "\n",
    "fig=go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Volume(\n",
    "        x=X.flatten(),\n",
    "        y=Y.flatten(),\n",
    "        z=Z.flatten(),\n",
    "        value=current_landmark_distribution_function_values,\n",
    "        opacity=0.9,\n",
    "        isomin=0.5e-3,\n",
    "        surface_count=surface_count,\n",
    "        colorbar=dict(lenmode='pixels', len=1000, thickness=50, tickfont=dict(size=30), x=1.01),\n",
    "        colorscale='YlGnBu'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1bc6b-a7b2-465a-81dc-b904365e27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    fig.update_layout(\n",
    "        title_text=(\"Landmarks distribution function<br><sup>\"+current_dataset_name+\"</sup>\"),\n",
    "        title_x=0.5,\n",
    "        scene_camera=scene_camera[0],\n",
    "        scene=dict(\n",
    "               #annotations=annotation_list,\n",
    "               #xaxis_visible=False, yaxis_visible=False, zaxis_visible=False\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    fig.update_layout(\n",
    "        title_text=(\"Landmarks distribution function<br><sup>\"+current_dataset_name+\"</sup>\"),\n",
    "        title_x=0.5,\n",
    "        scene=dict(\n",
    "               annotations=annotation_list,\n",
    "               #xaxis_visible=False, yaxis_visible=False, zaxis_visible=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.layout.height = 2000\n",
    "    fig.layout.width = fig.layout.height\n",
    "    fig.layout.margin.t = 0\n",
    "    fig.layout.margin.b = 0\n",
    "    fig.layout.margin.l = 0\n",
    "    fig.layout.margin.r = 0\n",
    "\n",
    "    fig.update_layout(title_text=\"\")\n",
    "\n",
    "    timestamp_string = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    timestamp_string = timestamp_string.replace('_2022_', '_22_')\n",
    "\n",
    "    folder = \"./Cranium_estimation_paper/Figures/PMF/\"\n",
    "    filetype = \".jpg\"\n",
    "    \n",
    "    for current_index in range(len(scene_camera[:1])):\n",
    "        fig.update_layout(scene_camera=scene_camera[current_index])\n",
    "        \n",
    "        filename = \"figure_PMF_\"+str(current_index)+\"_\"+str(joint_axis_grid_size)+\"_\"+str(marginal_axis_grid_size)+\"_\"+str(isomin_starting_percentile)+\"_\"+timestamp_string\n",
    "        path = folder + filename + filetype\n",
    "\n",
    "        pio.write_image(fig, path, scale=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e268d4-e9a2-467a-9fd2-6e97c392cce3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Joint probability distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b16b02-c784-4ccc-be9f-ef116ad7639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MI_mat = np.zeros((len(all_selected_indices_names), len(all_selected_indices_names)))\n",
    "MI_mat = np.zeros((len(all_selected_indices_names[len(light_landmarks):]), len(all_selected_indices_names[:len(light_landmarks)])))\n",
    "load_MI_mat = False\n",
    "\n",
    "if load_MI_mat:\n",
    "    array_folder = \"./3DMM/Head_instances/\"\n",
    "    array_filetype = '.npy'\n",
    "    \n",
    "    last_loaded_index = 0\n",
    "    \n",
    "    for current_landmark_index in range(len(all_selected_indices_names)):\n",
    "        current_index_name = all_selected_indices_names[current_landmark_index]\n",
    "        array_filename = (\"MI_\"+str(joint_axis_grid_size)+\"_\"+str(current_index_name))\n",
    "        array_path = array_folder + array_filename + array_filetype\n",
    "        \n",
    "        exists = os.path.exists(array_path)\n",
    "        \n",
    "        if not exists:\n",
    "            break\n",
    "        else:\n",
    "            with open(array_path, 'rb') as file:\n",
    "                current_landmark_MI_vals = np.load(file)\n",
    "            MI_mat[current_landmark_index, :] = current_landmark_MI_vals\n",
    "            last_loaded_index = current_landmark_index\n",
    "            \n",
    "    print(last_loaded_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f1ec1-f251-494d-bf65-73570f8637f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for desired_landmark_index_i, desired_landmark_name_i in enumerate(all_selected_indices_names[len(light_landmarks):]):\n",
    "    print((\"Started \" + desired_landmark_name_i))\n",
    "    if load_MI_mat:\n",
    "        if last_loaded_index>=desired_landmark_index_i:\n",
    "            continue       \n",
    "        \n",
    "    current_samples_i = skin_relevant_coordinates_df.loc[:, desired_landmark_name_i]\n",
    "    no_nan_rows_i = np.where(~current_samples_i.isnull().any(axis=1).values==True)[0]\n",
    "    no_zeros_rows_i = np.where(current_samples_i.values.all(axis=1))[0]\n",
    "    current_risk_estimation_samples_i = skin_relevant_coordinates_df.loc[bw_risk_estimation_indices, desired_landmark_name_i].values\n",
    "\n",
    "    for desired_landmark_index_j, desired_landmark_name_j in enumerate(all_selected_indices_names[:len(light_landmarks)]):\n",
    "        '''if desired_landmark_index_i==desired_landmark_index_j:\n",
    "            MI_mat[desired_landmark_index_i, desired_landmark_index_j] = 0\n",
    "        elif desired_landmark_index_i>desired_landmark_index_j:\n",
    "            MI_mat[desired_landmark_index_i, desired_landmark_index_j] = MI_mat[desired_landmark_index_j, desired_landmark_index_i]\n",
    "        else:'''\n",
    "        print((\"Started \" + desired_landmark_name_i + \" and \" + desired_landmark_name_j))\n",
    "        current_samples_j = skin_relevant_coordinates_df.loc[:, desired_landmark_name_j]\n",
    "        no_nan_rows_j = np.where(~current_samples_j.isnull().any(axis=1).values==True)[0]\n",
    "        no_zeros_rows_j = np.where(current_samples_j.values.all(axis=1))[0]\n",
    "        current_risk_estimation_samples_j = skin_relevant_coordinates_df.loc[bw_risk_estimation_indices, desired_landmark_name_j].values\n",
    "\n",
    "        no_nan_rows_ij = np.intersect1d(no_nan_rows_i, no_nan_rows_j)\n",
    "        no_zeros_rows_ij = np.intersect1d(no_zeros_rows_i, no_zeros_rows_j)\n",
    "        only_relevant_rows_ij = np.intersect1d(no_nan_rows_ij, no_zeros_rows_ij)\n",
    "        current_samples = np.concatenate([current_samples_i.iloc[only_relevant_rows_ij, :], current_samples_j.iloc[only_relevant_rows_ij, :]], axis=1)\n",
    "\n",
    "        current_risk_estimation_samples = np.concatenate([current_risk_estimation_samples_i, current_risk_estimation_samples_j], axis=1)\n",
    "\n",
    "        current_J = [kernel_based_empirical_risk(current_risk_estimation_samples, current_bw) for current_bw in bw_options]\n",
    "        selected_bw = bw_options[np.argmin(current_J)]\n",
    "        #selected_bw = 3.5\n",
    "        #print(selected_bw)\n",
    "\n",
    "        current_kde = KernelDensity(kernel=\"gaussian\", bandwidth=selected_bw)\n",
    "        current_kde.fit(current_samples)\n",
    "\n",
    "        x_coordinates_i = current_samples[:, 0]\n",
    "        x_coordinates_i_mean = np.mean(x_coordinates)\n",
    "        x_coordinates_i_std = np.std(x_coordinates)\n",
    "        x_min_i = x_coordinates_i_mean-3*x_coordinates_i_std\n",
    "        x_max_i = x_coordinates_i_mean+3*x_coordinates_i_std\n",
    "        x_bin_width_i = (x_max_i-x_min_i)/joint_axis_grid_size\n",
    "        x_grid_i = np.linspace(x_min_i+0.5*x_bin_width_i, x_max_i-0.5*x_bin_width_i, joint_axis_grid_size)\n",
    "\n",
    "        y_coordinates_i = current_samples[:, 1]\n",
    "        y_coordinates_i_mean = np.mean(y_coordinates)\n",
    "        y_coordinates_i_std = np.std(y_coordinates)\n",
    "        y_min_i = y_coordinates_i_mean-3*y_coordinates_i_std\n",
    "        y_max_i = y_coordinates_i_mean+3*y_coordinates_i_std\n",
    "        y_bin_width_i = (y_max_i-y_min_i)/joint_axis_grid_size\n",
    "        y_grid_i = np.linspace(y_min_i+0.5*y_bin_width_i, y_max_i-0.5*y_bin_width_i, joint_axis_grid_size)\n",
    "\n",
    "        z_coordinates_i = current_samples[:, 2]\n",
    "        z_coordinates_i_mean = np.mean(z_coordinates)\n",
    "        z_coordinates_i_std = np.std(z_coordinates)\n",
    "        z_min_i = z_coordinates_i_mean-3*z_coordinates_i_std\n",
    "        z_max_i = z_coordinates_i_mean+3*z_coordinates_i_std\n",
    "        z_bin_width_i = (z_max_i-z_min_i)/joint_axis_grid_size\n",
    "        z_grid_i = np.linspace(z_min_i+0.5*z_bin_width_i, z_max_i-0.5*z_bin_width_i, joint_axis_grid_size)\n",
    "\n",
    "        x_coordinates_j = current_samples[:, 3]\n",
    "        x_coordinates_j_mean = np.mean(x_coordinates)\n",
    "        x_coordinates_j_std = np.std(x_coordinates)\n",
    "        x_min_j = x_coordinates_j_mean-3*x_coordinates_j_std\n",
    "        x_max_j = x_coordinates_j_mean+3*x_coordinates_j_std\n",
    "        x_bin_width_j = (x_max_j-x_min_j)/joint_axis_grid_size\n",
    "        x_grid_j = np.linspace(x_min_j+0.5*x_bin_width_j, x_max_j-0.5*x_bin_width_j, joint_axis_grid_size)\n",
    "\n",
    "        y_coordinates_j = current_samples[:, 4]\n",
    "        y_coordinates_j_mean = np.mean(y_coordinates)\n",
    "        y_coordinates_j_std = np.std(y_coordinates)\n",
    "        y_min_j = y_coordinates_j_mean-3*y_coordinates_j_std\n",
    "        y_max_j = y_coordinates_j_mean+3*y_coordinates_j_std\n",
    "        y_bin_width_j = (y_max_j-y_min_j)/joint_axis_grid_size\n",
    "        y_grid_j = np.linspace(y_min_j+0.5*y_bin_width_j, y_max_j-0.5*y_bin_width_j, joint_axis_grid_size)\n",
    "\n",
    "        z_coordinates_j = current_samples[:, 5]\n",
    "        z_coordinates_j_mean = np.mean(z_coordinates)\n",
    "        z_coordinates_j_std = np.std(z_coordinates)\n",
    "        z_min_j = z_coordinates_j_mean-3*z_coordinates_j_std\n",
    "        z_max_j = z_coordinates_j_mean+3*z_coordinates_j_std\n",
    "        z_bin_width_j = (z_max_j-z_min_j)/joint_axis_grid_size\n",
    "        z_grid_j = np.linspace(z_min_j+0.5*z_bin_width_j, z_max_j-0.5*z_bin_width_j, joint_axis_grid_size)\n",
    "\n",
    "        X_i, Y_i, Z_i, X_j, Y_j, Z_j = np.meshgrid(x_grid_i, y_grid_i, z_grid_i, x_grid_j, y_grid_j, z_grid_j)\n",
    "        xyz_i_xyz_j = np.vstack([X_i.ravel(), Y_i.ravel(), Z_i.ravel(), X_j.ravel(), Y_j.ravel(), Z_j.ravel()]).T\n",
    "\n",
    "        joint_distribution_function_values = current_kde.score_samples(xyz_i_xyz_j)\n",
    "        joint_distribution_function_values = np.exp(joint_distribution_function_values)\n",
    "        try:\n",
    "            joint_distribution_function_values = joint_distribution_function_values/np.sum(joint_distribution_function_values)\n",
    "        except:\n",
    "            joint_distribution_function_values = 0\n",
    "\n",
    "        distribution_function_values_i = distribution_function_values_mat[desired_landmark_index_i, :]\n",
    "        distribution_function_values_j = distribution_function_values_mat[desired_landmark_index_j, :]\n",
    "\n",
    "        current_MI = 0\n",
    "\n",
    "        for i in range(distribution_function_values_i.shape[0]):\n",
    "            i_distribution_value = distribution_function_values_i[i]\n",
    "            nan_counter=0\n",
    "            for j in range(distribution_function_values_j.shape[0]):\n",
    "                j_distribution_value = distribution_function_values_j[j]\n",
    "                joint_distribution_value = joint_distribution_function_values[i*distribution_function_values_j.shape[0] + j]\n",
    "                try:\n",
    "                    current_MI+=joint_distribution_value*np.log(joint_distribution_value/(i_distribution_value*j_distribution_value))\n",
    "                except:\n",
    "                    nan_counter+=1\n",
    "            if nan_counter>0:\n",
    "                current_MI = current_MI*(distribution_function_values_j.shape[0]/(distribution_function_values_j.shape[0]-nan_counter))\n",
    "        MI_mat[desired_landmark_index_i, desired_landmark_index_j] = current_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e3d65-dca7-433a-9e8e-d3316acbf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    array_folder = \"./3DMM/Statistical_analysis/\"\n",
    "    array_filename = (current_dataset_name+\"_joint_PMF_\"+str(joint_axis_grid_size))\n",
    "    array_filetype = '.npy'\n",
    "\n",
    "    array_path = array_folder + array_filename + array_filetype\n",
    "\n",
    "    with open(array_path, 'wb') as file:\n",
    "        np.save(file, joint_distribution_function_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e4041-cf67-4a6b-9fd8-ace5c22b1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    array_folder = \"./3DMM/Statistical_analysis/\"\n",
    "    array_filename = (current_dataset_name+\"_MI_mat_\"+str(joint_axis_grid_size))\n",
    "    array_filetype = '.npy'\n",
    "\n",
    "    array_path = array_folder + array_filename + array_filetype\n",
    "\n",
    "    with open(array_path, 'wb') as file:\n",
    "        np.save(file, MI_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1a4c1-e13b-4b16-91b8-0b8c72ad09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_folder = \"./3DMM/Statistical_analysis/\"\n",
    "array_filename = (\"IXI_MI_mat_\"+str(4))\n",
    "array_filetype = '.npy'\n",
    "\n",
    "array_path = array_folder + array_filename + array_filetype\n",
    "\n",
    "with open(array_path, 'rb') as file:\n",
    "    IXI_MI_mat = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fc370-3aef-4de8-93fb-60d6af919239",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_folder = \"./3DMM/Statistical_analysis/\"\n",
    "array_filename = (\"ADNI_MI_mat_\"+str(4))\n",
    "array_filetype = '.npy'\n",
    "\n",
    "array_path = array_folder + array_filename + array_filetype\n",
    "\n",
    "with open(array_path, 'rb') as file:\n",
    "    ADNI_MI_mat = np.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9845e6d4-ef84-496e-b9b6-eff35417dab4",
   "metadata": {},
   "source": [
    "## Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1d9cc-0590-4e2a-b4a2-de1b11f90ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_saver(fig, filename):\n",
    "    \n",
    "    pio.kaleido.scope.mathjax = None\n",
    "\n",
    "    timestamp_string = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    timestamp_string = timestamp_string.replace('_2022_', '_22_')\n",
    "\n",
    "    figure_folder = \"./Cranium_estimation_paper/Figures/Mutual_information/\"\n",
    "    figure_filename = f\"{filename}_{timestamp_string}\" #???\"experiment_\"+str(experiment_number)+\"_\"+timestamp_string+\"_\"+filename\n",
    "    figure_filetype = \".eps\"\n",
    "\n",
    "    figure_path = figure_folder + figure_filename + figure_filetype\n",
    "\n",
    "    fig.layout.title = \"\"\n",
    "    \n",
    "    fig.layout.margin.t = 0\n",
    "    fig.layout.margin.b = 0\n",
    "    fig.layout.margin.l = 0\n",
    "    fig.layout.margin.r = 10\n",
    "\n",
    "    pio.write_image(fig, figure_path)#, scale=5)\n",
    "    pio.write_json(fig, file=figure_folder+figure_filename+\".json\" ,validate=True, pretty=True, remove_uids=False, engine='json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54d4f9-3690-4e26-8047-c2279357d8b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Landmark coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb06b6-6484-417d-a595-a50948067eb2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_filename = f\"IXI_MI_{joint_axis_grid_size}\"\n",
    "IXI_MI_fig = px.imshow(\n",
    "    MI_mat.T,\n",
    "    x=list(all_selected_indices_names[len(light_landmarks):]),\n",
    "    y=list(all_selected_indices_names[:len(light_landmarks)]),\n",
    "    color_continuous_scale=px.colors.sequential.YlGnBu\n",
    ")\n",
    "\n",
    "IXI_MI_fig.update_layout(\n",
    "    title=f\"{current_dataset_name} landmark positions mutual information matrix, joint_axis_grid_size={joint_axis_grid_size}\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "IXI_MI_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5ce0c-dcdf-4b0f-b15f-f1e7fe3198ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_saver(IXI_MI_fig, current_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44296c8-a263-47e7-a4bb-0f659e98c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_filename = f\"ADNI_MI_{joint_axis_grid_size}\"\n",
    "ADNI_MI_fig = px.imshow(\n",
    "    MI_mat.T,\n",
    "    x=list(all_selected_indices_names[len(light_landmarks):]),\n",
    "    y=list(all_selected_indices_names[:len(light_landmarks)]),\n",
    "    #height=400,\n",
    "    color_continuous_scale=px.colors.sequential.YlGnBu\n",
    ")\n",
    "\n",
    "ADNI_MI_fig.update_layout(\n",
    "    title=f\"{current_dataset_name} landmark positions mutual information matrix, joint_axis_grid_size={joint_axis_grid_size}\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "IXI_MI_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23678e82-91be-4732-8c7a-589d9d3841de",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_saver(ADNI_MI_fig, current_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b0f8c-54d8-4608-a690-7af076b10824",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_filename = f'Unified_MI_{joint_axis_grid_size}'\n",
    "color_palette = px.colors.qualitative.Dark24 #Light24\n",
    "\n",
    "fig_unified_MI = make_subplots(rows=2,\n",
    "                               cols=1,\n",
    "                               horizontal_spacing=0,\n",
    "                               vertical_spacing=0.025,\n",
    "                               shared_xaxes=True,\n",
    "                               shared_yaxes=True,\n",
    "                               x_title='Landmark',\n",
    "                               y_title='Mutual information value',\n",
    "                               row_titles=['IXI',\n",
    "                                           'ADNI']\n",
    "                                )\n",
    "\n",
    "fig_unified_MI.add_trace(go.Heatmap(\n",
    "    z=np.flipud(IXI_MI_mat.T),\n",
    "    x=list(all_selected_indices_names[len(light_landmarks):]),\n",
    "    y=list(all_selected_indices_names[:len(light_landmarks)])[::-1],\n",
    "    coloraxis = \"coloraxis\"\n",
    "), 1, 1\n",
    "                        )\n",
    "\n",
    "fig_unified_MI.add_trace(go.Heatmap(\n",
    "    z=np.flipud(ADNI_MI_mat.T),\n",
    "    x=list(all_selected_indices_names[len(light_landmarks):]),\n",
    "    y=list(all_selected_indices_names[:len(light_landmarks)])[::-1],\n",
    "    coloraxis = \"coloraxis\"\n",
    "), 2, 1\n",
    "                        )\n",
    "\n",
    "fig_unified_MI.update_layout(\n",
    "    height=1000,\n",
    "    coloraxis = {'colorscale':'YlGnBu'},\n",
    "    font = dict(size=12, family=\"Times new roman\"),\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "    ),\n",
    "\n",
    ")\n",
    "                                      \n",
    "fig_unified_MI.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe545bd-ab2e-4935-8a4d-44736042c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_saver(fig_unified_MI, current_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3899e01-9a93-4d02-8d8d-a2128378566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    figure_folder = \"./Cranium_estimation_paper/Figures/Mutual_information/\"\n",
    "    figure_filetype = \".jpg\"\n",
    "    figure_filename = (\"full_landmarks_position_\"+str(joint_axis_grid_size)+\"_\"+filename)\n",
    "\n",
    "    figure_path = figure_folder + figure_filename + figure_filetype\n",
    "\n",
    "    fig.layout.title = \"\"\n",
    "    fig.update_layout(coloraxis_colorbar=dict(x=0.8))\n",
    "    \n",
    "    pio.write_image(fig, figure_path, scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70b93e-fa38-4ae9-afb4-b986688eff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10_20_EEG_landmark_index=np.where(all_selected_indices_names=='Fz')[0]\n",
    "indices_10_20_EEG = np.arange(first_10_20_EEG_landmark_index, all_selected_indices_names.shape[0])\n",
    "indices_face = np.arange(first_10_20_EEG_landmark_index-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf189604-a4de-49ff-9611-80244717a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_mat_selected_rows = np.take(MI_mat, indices_10_20_EEG, axis=0)\n",
    "MI_mat_selected_rows_cols = np.take(MI_mat_selected_rows, indices_face, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18359ffa-d7b3-43c7-bd26-9e73c8509afa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(MI_mat_selected_rows_cols , x=all_selected_indices_names[indices_face], y=all_selected_indices_names[indices_10_20_EEG], height=400, color_continuous_scale=px.colors.sequential.YlGnBu)\n",
    "fig.update_layout(title=\"Landmarks mutual information matrix<br><sup>\"+fixed_filename+\"</sup>\", title_x=0.5, font=dict(size=7))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29829963-588b-45f9-8594-370e1f316517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    figure_folder = \"./Cranium_estimation_paper/Figures/Mutual_information/\"\n",
    "    figure_filetype = \".jpg\"\n",
    "    figure_filename = (\"selected_landmarks_position_\"+str(joint_axis_grid_size)+\"_\"+filename)\n",
    "\n",
    "    figure_path = figure_folder + figure_filename + figure_filetype\n",
    "\n",
    "    fig.layout.title = \"\"\n",
    "    fig.update_layout(coloraxis_colorbar=dict(x=1.01))\n",
    "    \n",
    "    pio.write_image(fig, figure_path, scale=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
