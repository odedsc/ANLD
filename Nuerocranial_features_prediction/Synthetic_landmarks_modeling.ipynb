{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89b7fd0-4540-4cfc-a1be-be0a5917e931",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading and disaplying the 3DMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import plotly.io as pio\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn.functional as F\n",
    "from Prediction_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109a8c8-9e20-4767-9008-c5694e3ee54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_folder = \"./datasets/TMS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7dba2-17ff-4423-89ee-a9f6c1a407b3",
   "metadata": {},
   "source": [
    "## Original model including everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdbc6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "models_folder = media_folder+'/3DMM/UHM_models/'\n",
    "currnet_model = 'UHM' \n",
    "\n",
    "# UHM model with all the components fused together (i.e. ears, inner mouth, and teeth)\n",
    "model_name = 'head_model_global_align'\n",
    "\n",
    "model_file = open(models_folder + model_name + '.pkl', 'rb')\n",
    "model_dict = pickle.load(model_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning coordinates system to be in millimeter units\n",
    "scale_factor = 100 \n",
    "\n",
    "# get model parameteres\n",
    "mean_shape = scale_factor*model_dict['Mean']\n",
    "mean_shape_CCS = mean_shape.reshape(-1,3)\n",
    "eigen_vec = model_dict['Eigenvectors']\n",
    "eigen_vec_num =  model_dict['Eigenvectors'].shape[1]\n",
    "eigen_val = model_dict['EigenValues']\n",
    "trilist = model_dict['Trilist']\n",
    "vertices_num = model_dict['Number_of_vertices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules (landmarks and masks)\n",
    "modules_folder = models_folder + '/Landmarks and masks/'\n",
    "\n",
    "modules_to_load = ['68_land_idxs'] # EEG_10_20_full_model / '49_plus_ears_land_idxs' / '68_land_idxs'\n",
    "\n",
    "landmarks = []\n",
    "landmarks_names = []\n",
    "landmarks_groups = []\n",
    "\n",
    "for currnet_module_name in modules_to_load:\n",
    "    module_file = open(modules_folder + currnet_module_name + '.pkl', 'rb')\n",
    "    currnet_module = pickle.load(module_file)\n",
    "    module_file.close()\n",
    "    if currnet_module_name=='EEG_10_20':\n",
    "        currnet_module_names = list(currnet_module.keys())\n",
    "        currnet_module = np.asarray(list(currnet_module.values()))\n",
    "    else:\n",
    "        currnet_module_names = list(map(str, 1+np.arange(len(currnet_module))))\n",
    "        \n",
    "    landmarks.append(currnet_module)\n",
    "    landmarks_names.append(currnet_module_names)\n",
    "    landmarks_groups.append(np.arange(len(currnet_module)))\n",
    "\n",
    "# turn list of lists into one list\n",
    "landmarks = [item for items in landmarks for item in items]\n",
    "landmarks_names = [item for items in landmarks_names for item in items]\n",
    "\n",
    "num_of_landmarks = len(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3d161-79d4-4b57-bfb7-1637689b02d7",
   "metadata": {},
   "source": [
    "## Lighter model including everything but eyes, teeth and inner mouth cavity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6328036-ddc5-43cf-b6e4-b2796579a647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "light_models_folder = media_folder+'/3DMM/UHM_models/'\n",
    "light_currnet_model = 'UHM' \n",
    "\n",
    "# UHM model with all the components fused together (i.e. ears, inner mouth, and teeth)\n",
    "light_model_name = 'head_model_global_align_no_mouth_and_eyes'\n",
    "\n",
    "light_model_file = open(light_models_folder + light_model_name + '.pkl', 'rb')\n",
    "light_model_dict = pickle.load(light_model_file)\n",
    "light_model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3054a7-0bf9-48cf-b1a7-99fa02f11efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning cartesian coordinates system to be in millimeter units\n",
    "light_scale_factor = 100\n",
    "\n",
    "# get model parameteres\n",
    "light_mean_shape = light_scale_factor*light_model_dict['Mean']\n",
    "light_mean_shape_CCS = light_mean_shape.reshape(-1,3)\n",
    "light_eigen_vec = light_model_dict['Eigenvectors']\n",
    "light_eigen_vec_num =  light_model_dict['Eigenvectors'].shape[1]\n",
    "light_eigen_val = light_model_dict['EigenValues']\n",
    "light_trilist = light_model_dict['Trilist']\n",
    "light_vertices_num = light_model_dict['Number_of_vertices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6be30-d113-4343-b12f-517e24e459e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules (landmarks and masks)\n",
    "modules_folder = models_folder + '/Landmarks and masks/'\n",
    "\n",
    "modules_to_load = ['EEG_10_20'] # EEG_10_20 / '49_plus_ears_land_idxs' / '68_land_idxs'\n",
    "\n",
    "light_landmarks = []\n",
    "light_landmarks_names = []\n",
    "light_landmarks_groups = []\n",
    "\n",
    "for currnet_module_name in modules_to_load:\n",
    "    module_file = open(modules_folder + currnet_module_name + '.pkl', 'rb')\n",
    "    currnet_module = pickle.load(module_file)\n",
    "    module_file.close()\n",
    "    if currnet_module_name=='EEG_10_20':\n",
    "        currnet_module_names = list(currnet_module.keys())\n",
    "        currnet_module = np.asarray(list(currnet_module.values()))\n",
    "    else:\n",
    "        currnet_module_names = list(map(str, 1+np.arange(len(currnet_module))))\n",
    "        \n",
    "    light_landmarks.append(currnet_module)\n",
    "    light_landmarks_names.append(currnet_module_names)\n",
    "    light_landmarks_groups.append(np.arange(len(currnet_module)))\n",
    "\n",
    "# turn list of lists into one list\n",
    "light_landmarks = [item for items in light_landmarks for item in items]\n",
    "light_landmarks_names = [item for items in light_landmarks_names for item in items]\n",
    "\n",
    "num_of_light_landmarks = len(light_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e3cbd-5c01-47a2-99a8-59d172e4ed1a",
   "metadata": {},
   "source": [
    "## Matching landmark indices between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcca4c0-7085-49fe-a635-c5f4c42646cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_facial_landmarks = landmarks\n",
    "\n",
    "for current_landmark_index, current_landmark_vertex in enumerate(landmarks):\n",
    "    original_model_coordinates = mean_shape_CCS[current_landmark_vertex]\n",
    "    new_model_vertex_diffs = np.linalg.norm(light_mean_shape_CCS-original_model_coordinates, axis=1)\n",
    "    light_facial_landmarks[current_landmark_index] = np.argmin(new_model_vertex_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccb179-9d58-4b82-88e6-8c07aee0eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_nasion = 52241\n",
    "light_inion = 36323"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024dd8ed-ce45-4cab-9609-d8f73bc7edba",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3828c-2dee-4ac2-ac5b-fd8b7b18bc95",
   "metadata": {},
   "source": [
    "## Model Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f0ae0-e750-441c-9f05-a963acdba5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "choose_light_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db86eb-3571-4392-8a28-07aff4a9cc75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if choose_light_model:\n",
    "    landmarks = np.concatenate((light_landmarks, light_facial_landmarks, [light_nasion, light_inion]))\n",
    "    landmarks_names = list(np.concatenate((light_landmarks_names, landmarks_names, ['nasion', 'inion'])))\n",
    "    num_of_landmarks = len(landmarks_names)\n",
    "    mean_shape = light_mean_shape\n",
    "    mean_shape_CCS = light_mean_shape_CCS\n",
    "    eigen_vec = light_eigen_vec\n",
    "    eigen_vec_num =  light_eigen_vec_num\n",
    "    eigen_val = light_eigen_val\n",
    "    trilist = light_trilist\n",
    "    vertices_num = light_vertices_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68caad-7ef7-4ab4-95f5-0cd83246d41a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shape_trimesh = trimesh.Trimesh(vertices=mean_shape_CCS, faces=trilist, process=True)\n",
    "num_digits_round=4\n",
    "n_jobs_num=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfad12-7777-41e0-9a8e-05b8334af447",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_landmarks_names = np.array([37, 40, 43, 46, 49, 55, 31, 9])\n",
    "rigid_facial_landmarks_names = np.array([37, 40, 43, 46, 28, 1, 17])\n",
    "\n",
    "center_of_the_eyebrows = np.array([20, 25])\n",
    "corners_of_the_eyebrows = np.array([18, 22, 23, 27])\n",
    "corners_of_the_eyes = np.array([37, 40, 43, 46])\n",
    "sides_of_the_face = np.array([1, 17])\n",
    "nose_bone = np.array([28, 31])\n",
    "lower_nose = np.array([32, 34, 36])\n",
    "corners_of_the_mouth = np.array([49, 55])\n",
    "chin = np.array([9])\n",
    "\n",
    "facial_landmarks = np.concatenate((center_of_the_eyebrows, corners_of_the_eyebrows, corners_of_the_eyes, sides_of_the_face, nose_bone, lower_nose,\n",
    "                                   corners_of_the_mouth, chin))\n",
    "selected_facial_indices = np.sort(facial_landmarks+num_of_light_landmarks-1)\n",
    "\n",
    "selected_EEG_10_20_landmark_names = light_landmarks_names\n",
    "selected_EEG_10_20_indices = []\n",
    "for current_index, current_landmark_name in enumerate(selected_EEG_10_20_landmark_names):\n",
    "    selected_EEG_10_20_indices.append(landmarks_names.index(current_landmark_name))\n",
    "selected_EEG_10_20_indices = np.asarray(selected_EEG_10_20_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88714baa-8021-4930-a592-6bfc11a73270",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_landmarks = ['1', '2', '3', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27',\n",
    "                   '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42',\n",
    "                   '43', '44', '45', '46', '47', '48', '69', '70']\n",
    "input_landmarks = [int(current_landmark) for current_landmark in input_landmarks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92549f2c-63c7-47a2-8634-4d6344e5c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = np.concatenate((selected_EEG_10_20_indices, 20+np.array(input_landmarks)))\n",
    "selected_indices_names = np.take(landmarks_names, selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fcc0b-9003-4a90-9cd3-867b917f447a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_sets = {}\n",
    "feature_sets['eye corners & eyebrow corners'] = np.concatenate((corners_of_the_eyebrows, corners_of_the_eyes))\n",
    "feature_sets['eye corners & eyebrow centers'] = np.concatenate((center_of_the_eyebrows, corners_of_the_eyes))\n",
    "feature_sets['eye corners & eyebrow corners and center'] = np.concatenate((center_of_the_eyebrows, corners_of_the_eyebrows, corners_of_the_eyes))\n",
    "feature_sets['eye corners & nose bone'] = np.concatenate((corners_of_the_eyes, nose_bone))\n",
    "feature_sets['nose bone & lower nose'] = np.concatenate((nose_bone, lower_nose))\n",
    "feature_sets['input_landmarks'] = np.array(input_landmarks[:-2])\n",
    "\n",
    "for current_key in feature_sets:\n",
    "    feature_sets[current_key] = feature_sets[current_key]+num_of_light_landmarks-1\n",
    "    feature_sets[current_key] = list(map(str, feature_sets[current_key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3da6b9-bcf9-428b-aea2-5c66ecb65daf",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae22bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe03d9-f149-4c81-bda4-6a6ea160c4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead3491-14b7-4bfb-a6df-9733af7dc3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d97d21e8-fd50-476a-bffa-fa6dfbbe422d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading instances dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d73e8-fac7-4e3f-bae1-729ee8a3d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = media_folder+\"/3DMM/Head_instances/\"\n",
    "filetype = \".xlsx\"\n",
    "fixed_filename = \"dataset\" \n",
    "fixed_path = folder + fixed_filename + filetype\n",
    "\n",
    "excel_file = pd.ExcelFile(fixed_path, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e020d27-6556-4a91-94c6-abc3eb9bea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read facial features coordinates from an excel file as multiindex\n",
    "fixed_landmarks_coordinates_df=pd.read_excel(fixed_path, header=[0,1], index_col=0, sheet_name=('coordinates_' + str(1)), engine='openpyxl')\n",
    "fixed_geodesic_distances_df=pd.read_excel(fixed_path, index_col=0, sheet_name=('geodesic_' + str(1)), engine='openpyxl')\n",
    "\n",
    "fixed_num_of_instances = fixed_landmarks_coordinates_df.shape[0]\n",
    "fixed_landmarks_coordinates_df = fixed_landmarks_coordinates_df/1000\n",
    "fixed_geodesic_distances_df = fixed_geodesic_distances_df/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177ef6a-1435-4294-acda-629e3987f120",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Landmark Predictions - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8e116-9b20-419e-9e65-971fa265049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_nn = MLP_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625f733-8149-4ee2-bb75-8464d274323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = False\n",
    "save_arrays = True\n",
    "load_arrays = False\n",
    "save_model = True\n",
    "regressor_name='pytorch_MLP'\n",
    "regressor_models_folder = media_folder+'/3DMM/Trained_models/' + regressor_name + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84b979-e3f8-4f23-a5e8-0f95f4a89a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "test_size=0.0001\n",
    "\n",
    "train_indices = np.sort(np.random.choice(range(fixed_landmarks_coordinates_df.shape[0]),\n",
    "                                         #1, replace=False))\n",
    "                                 int(fixed_landmarks_coordinates_df.shape[0]*(1-test_size)), replace=False))\n",
    "test_indices = np.setdiff1d(np.arange(fixed_landmarks_coordinates_df.shape[0]), train_indices)#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051fbda-c096-4bef-8255-50a53a9ca007",
   "metadata": {},
   "source": [
    "## Predict coordinates using coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc5438-0233-4af4-aade-73f6402d22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = 1\n",
    "\n",
    "experiment_model_filename = 'Coordinates/'+MLP_folder+'3DMM/'\n",
    "experiment_model_path = regressor_models_folder + experiment_model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437fdc8-a740-4bfb-88f6-2eaf3d5f9492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "if load_arrays==False:\n",
    "    coordinates_coordinates_resolutions_MSE_array = np.zeros((len(selected_EEG_10_20_indices),))\n",
    "    coordinates_coordinates_resolutions_std_array = np.zeros((len(selected_EEG_10_20_indices),))\n",
    "    validation_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    feature_set_index=len(list(feature_sets.keys()))-1\n",
    "\n",
    "    current_features = feature_sets[list(feature_sets.keys())[feature_set_index]]\n",
    "    for desired_landmark_index, desired_landmark_name in enumerate((np.take(landmarks_names, selected_EEG_10_20_indices))):\n",
    "        model, coordinates_coordinates_resolutions_MSE_array[desired_landmark_index], _, coordinates_coordinates_resolutions_std_array[\n",
    "            desired_landmark_index], scaler, means, validation_loss, test_loss = coordinates_by_coordinates_regression(\n",
    "            fixed_landmarks_coordinates_df, train_indices, test_indices, current_features, desired_landmark_index, landmarks_names, regressor_name)\n",
    "\n",
    "        validation_losses.append(validation_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(1000*np.sqrt(coordinates_coordinates_resolutions_MSE_array[desired_landmark_index]))\n",
    "\n",
    "        if save_model:\n",
    "            timestamp_string = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "            timestamp_string = timestamp_string.replace('_2022_', '_22_')\n",
    "\n",
    "            torch.save(model.state_dict(), experiment_model_path+timestamp_string+'_'+desired_landmark_name+'_model')\n",
    "            pickle.dump(scaler, open(experiment_model_path+timestamp_string+'_'+desired_landmark_name+'_scaler.pkl', 'wb'))\n",
    "            documentation = [\n",
    "                f\"predicted_landmark_name: {desired_landmark_name}\",\n",
    "                f\"landmark_names_being_used: {list(np.sort(np.array(list(map(int, current_features)))-20))}\",\n",
    "                f\"number_of_training_samples: {train_indices.size}\",\n",
    "                f\"means: {means}\",\n",
    "                f\"model: {model}\",\n",
    "            ]\n",
    "            with open(experiment_model_path+timestamp_string+'_'+desired_landmark_name+'_documentation.txt' , \"w\") as txt_file:\n",
    "                txt_file.write(\"\\n\".join(documentation))\n",
    "\n",
    "        print(f\"Finished {desired_landmark_name}, {desired_landmark_index+1}/{len(selected_EEG_10_20_indices)}\")\n",
    "\n",
    "else:\n",
    "    coordinates_coordinates_resolutions_MSE_array, coordinates_coordinates_resolutions_std_array = experiment_arrays_loader(media_folder, regressor_name, experiment_number)\n",
    "    save_arrays = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa09eb75-68d4-44b2-b9a6-8d3f62ad63b3",
   "metadata": {},
   "source": [
    "## Predict coordinates using coordinates and geodesic distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6abf65-2c51-49fa-86a2-a03fb017477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = 2\n",
    "\n",
    "experiment_model_filename = 'Coordinates_Geodesic/'+MLP_folder+'3DMM/'\n",
    "\n",
    "experiment_model_path = regressor_models_folder + experiment_model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90204f1-9606-419a-bcc9-cf3f6af8db52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "if load_arrays==False:\n",
    "    coordinates_coordinates_resolutions_MSE_array = np.zeros((len(selected_EEG_10_20_indices),))\n",
    "    coordinates_coordinates_resolutions_std_array = np.zeros((len(selected_EEG_10_20_indices),))\n",
    "    validation_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    feature_set_index=len(list(feature_sets.keys()))-1\n",
    "\n",
    "    current_features = feature_sets[list(feature_sets.keys())[feature_set_index]]\n",
    "    for desired_landmark_index, desired_landmark_name in enumerate((np.take(landmarks_names, selected_EEG_10_20_indices))):\n",
    "        \n",
    "        model, coordinates_coordinates_resolutions_MSE_array[desired_landmark_index], _, coordinates_coordinates_resolutions_std_array[\n",
    "            desired_landmark_index], scaler, means, validation_loss, test_loss = coordinates_by_coordinates_and_geodesic_distance_regression(\n",
    "            fixed_landmarks_coordinates_df, fixed_geodesic_distances_df, train_indices, test_indices,current_features,\n",
    "            desired_landmark_index, landmarks_names, regressor_name)\n",
    "\n",
    "        validation_losses.append(validation_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(1000*np.sqrt(coordinates_coordinates_resolutions_MSE_array[desired_landmark_index]))\n",
    "\n",
    "        if save_model:\n",
    "            timestamp_string = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "            timestamp_string = timestamp_string.replace('_2022_', '_22_')\n",
    "\n",
    "            torch.save(model.state_dict(), experiment_model_path+timestamp_string+'_'+desired_landmark_name+'_model')\n",
    "            pickle.dump(scaler, open(experiment_model_path+timestamp_string+'_'+desired_landmark_name+'_scaler.pkl', 'wb'))\n",
    "            documentation = [\n",
    "                f\"predicted_landmark_name: {desired_landmark_name}\",\n",
    "                f\"landmark_names_being_used: {list(np.sort(np.array(list(map(int, current_features)))-20))}\",\n",
    "                f\"number_of_training_samples: {train_indices.size}\",\n",
    "                f\"means: {means}\",\n",
    "                f\"model: {model}\",\n",
    "            ]\n",
    "            with open(experiment_model_path+timestamp_string+'_'+desired_landmark_name+'_documentation.txt' , \"w\") as txt_file:\n",
    "                txt_file.write(\"\\n\".join(documentation))\n",
    "\n",
    "        print(f\"Finished {desired_landmark_name}, {desired_landmark_index+1}/{len(selected_EEG_10_20_indices)}\")\n",
    "\n",
    "else:\n",
    "    coordinates_coordinates_resolutions_MSE_array, coordinates_coordinates_resolutions_std_array = experiment_arrays_loader(media_folder, regressor_name, experiment_number)\n",
    "    save_arrays = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
